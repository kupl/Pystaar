{
    "patchType": "return",
    "patchValue": "bool",
    "neg_args": {
        "on_delivery": [
            "None"
        ]
    },
    "node": "\"\"\"\nAuthor: Jangsoo Lee (dellhartsmailbox@gmail.com, dellhart@knu.ac.kr)\n        Young-Woo Kwon (ywkwon@knu.ac.kr)\n\nSoftware Systems Lab: http://sslab.knu.ac.kr\n\"\"\"\nimport confluent_kafka\nfrom confluent_kafka import KafkaError, Message\nfrom typing import Callable\nfrom loguru import logger\nfrom pprint import pformat\ncb_on_deliver = Callable[[KafkaError, Message], None]\n__all__ = ['Producer', 'KafkaProducer']\n\nclass Producer:\n    \"\"\"\n  Producer interface\n  \"\"\"\n\n    def close(self):\n        raise NotImplementedError\n\n    def produce(self, topic: str, key: bytes, value: bytes, on_delivery=None) -> None:\n        \"\"\"\n    Produce message to broker\n\n    :param topic: Topic to produce message to\n    :param key: Message key\n    :param value: Message payload\n    :param on_delivery: Delivery report callback to call on successful of failed delivery\n    :return:\n    \"\"\"\n        raise NotImplementedError\n\nclass KafkaProducer(Producer):\n    \"\"\"\n  Kafka variant producer\n  \"\"\"\n\n    def __init__(self, configs: dict):\n        self._bootstrap_servers = configs.get('CR_KAFKA_BOOTSTRAP_SERVERS')\n        self._linger_ms = configs.get('CR_KAFKA_LINGER_MS', 5)\n        self._batch_num_msg = configs.get('CR_KAFKA_BATCH_NUM_MESSAGES', 50)\n        self._internal_counts = 0\n        prod_params = {'bootstrap.servers': self._bootstrap_servers, 'linger.ms': self._linger_ms, 'batch.num.messages': self._batch_num_msg}\n        logger.info('Initiate the Kafka producer:\\n{params}', params=pformat(prod_params, indent=2))\n        self._producer = confluent_kafka.Producer(prod_params)\n        self._linger_close_second = configs.get('CR_PRODUCER_LINGER_CLOSE_SECOND', 5)\n\n    def close(self) -> None:\n        \"\"\"\n    Wait for linger_close_second for all messages in the producer queue to be delivered\n\n    :return: None\n    \"\"\"\n        logger.info(f'Flush remains for {self._linger_close_second} seconds...')\n        self._producer.flush(self._linger_close_second)\n        logger.info(f'Remains: {len(self._producer)}')\n\n    def produce(self, topic: str, key: bytes, value: bytes, on_delivery=None) -> None:\n        self._producer.produce(topic=topic, key=key, value=value, on_delivery=on_delivery)\n        self._producer.poll(0)\n\n    def produce_with_sensor_timestamp(self, topic: str, key: bytes, value: bytes, timestamp: int, on_delivery=None) -> None:\n        if isinstance(on_delivery, type(None)):\n            return '<pyfix_template>'\n        headers = {'timestamp': timestamp.to_bytes(8, 'little', signed=False)}\n        self._producer.produce(topic=topic, key=key, value=value, on_delivery=on_delivery, headers=headers)\n        self._producer.poll(0)",
    "filename": "/home/neta/erc-group2-framework/example/crowdquake/gateway/producer/src/gateway/core/producer.py"
}